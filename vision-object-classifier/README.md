# ğŸ” Vision Object Classifier

**Advanced computer vision system for household object cleanliness classification using deep learning and synthetic data generation**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Revolutionary dish cleanliness classifier that overcomes limited dataset availability through advanced synthetic data generation. Achieves production-ready accuracy with resource-efficient training optimized for local development.

## âœ¨ Key Features

- **ğŸ¯ 85% classification accuracy** with synthetic data only (250 total images)
- **ğŸ”® Synthetic data generation** - Create unlimited realistic dirty dish variants
- **âš¡ Multiple model architectures** - Custom CNN, ResNet50, EfficientNet, MobileNet
- **ğŸ’» Local training optimization** - Runs efficiently on regular laptops
- **ğŸ”„ Dual data strategy** - Synthetic generation + optional Kaggle integration
- **ğŸ“Š Production-ready inference** - High-confidence predictions with visualization
- **ğŸ› ï¸ Zero-dependency fallback** - Works without external APIs or datasets

## ğŸ¯ Performance Results

| **Metric** | **Clean Detection** | **Dirty Detection** | **Overall** |
|------------|-------------------|-------------------|-------------|
| **Accuracy** | 100% | 70% | 85% |
| **Confidence Range** | 0.91-0.93 | 0.80-1.00 | 0.78-1.00 |
| **Training Time** | <5 minutes | <5 minutes | <5 minutes |

## ğŸš€ Quick Start

Get from clone to classification in under 5 minutes:

```bash
# 1. Clone and setup
git clone https://github.com/joshamorrison/public.git
cd public/vision-object-classifier

# 2. Create virtual environment (recommended)
python -m venv venv
source venv/Scripts/activate  # Windows
# source venv/bin/activate    # macOS/Linux

# 3. Install dependencies (~2 minutes)
pip install -r requirements.txt

# 4. Run the demo (~30 seconds)
python quick_start.py
```

**Expected Output:**
```
=== Vision Object Classifier - Quick Start Demo ===

1. Testing Clean Plate (Synthetic) (expecting: Clean)
   Result: Clean (confidence: 0.9207)
   SUCCESS: Correct prediction!

2. Testing Dirty Plate (Synthetic) (expecting: Dirty)
   Result: Dirty (confidence: 0.9922)
   SUCCESS: Correct prediction!

3. Testing Real-World Dirty Dish (Pasta Stains) (expecting: Dirty)
   Result: Dirty (confidence: 1.0000)
   SUCCESS: Correct prediction!

=== DEMO RESULTS ===
Successful predictions: 3/3
SUCCESS: All demo tests passed! The system is working correctly.
```

## ğŸ“ Project Structure

```
vision-object-classifier/
â”œâ”€â”€ src/                          # Python package (proper src layout)
â”‚   â””â”€â”€ vision_classifier/        # Main package
â”‚       â”œâ”€â”€ model.py             # Neural network architectures
â”‚       â”œâ”€â”€ data_utils.py        # Data loading and preprocessing
â”‚       â”œâ”€â”€ synthetic_data.py    # Advanced synthetic data generation
â”‚       â”œâ”€â”€ train.py             # Training pipeline with optimization
â”‚       â””â”€â”€ predict.py           # Inference engine with batch processing
â”œâ”€â”€ data/                        # Training data
â”‚   â”œâ”€â”€ clean/                   # Clean dish images (70 samples)
â”‚   â””â”€â”€ dirty/                   # Dirty dish images (140 synthetic variants)
â”œâ”€â”€ models/                      # Trained model checkpoints
â”œâ”€â”€ scripts/                     # Utility scripts
â”œâ”€â”€ tests/                       # Comprehensive unit test suite
â”œâ”€â”€ docs/                        # Detailed documentation
â””â”€â”€ quick_start.py               # Main demo & entry point
```

## ğŸ’» Usage Examples

### Basic Prediction
```python
from src.vision_classifier.predict import DishCleanlinessPredictor

# Initialize predictor with trained model
predictor = DishCleanlinessPredictor(
    model_path='models/final_balanced_model.pth',
    config_path='models/balanced_config.json'
)

# Single image prediction
result = predictor.predict_single('dish_image.jpg')
print(f"Prediction: {result['class_name']}")
print(f"Confidence: {result['confidence']:.3f}")
```

### Synthetic Data Generation
```python
from src.vision_classifier.synthetic_data import SyntheticDirtyDishGenerator

# Generate realistic dirty variants
generator = SyntheticDirtyDishGenerator('data/dirty')
total_generated = generator.batch_generate(
    clean_images_dir='data/clean',
    num_variations=5  # Creates 5 dirty variants per clean image
)
print(f"Generated {total_generated} dirty images")
```

### Custom Training
```python
# Add your own images and retrain
# 1. Put clean dish photos in: data/clean/
# 2. Put dirty dish photos in: data/dirty/

# Train with your custom dataset
python src/train.py

# Test your custom model
python src/predict.py --model models/final_balanced_model.pth --config models/balanced_config.json --image YOUR_TEST_IMAGE.jpg
```

### Command Line Interface
```bash
# Single image classification
python src/predict.py --model models/final_balanced_model.pth --config models/balanced_config.json --image dish.jpg

# Batch processing with visualization
python src/predict.py --model models/final_balanced_model.pth --config models/balanced_config.json --image_dir test_images/ --output results/ --visualize

# Generate synthetic training data
python -c "
from src.vision_classifier.synthetic_data import SyntheticDirtyDishGenerator
generator = SyntheticDirtyDishGenerator('data/dirty')
generator.batch_generate('data/clean', num_variations=3)
"
```

## ğŸ”§ Configuration

### Model Architectures
- **Custom CNN** - Lightweight, optimized for local training (default)
- **ResNet50** - Pre-trained backbone for higher accuracy  
- **EfficientNet-B0** - Mobile-optimized architecture
- **MobileNet-V3** - Ultra-lightweight for real-time inference

### Data Enhancement Options
```bash
# Option 1: Generate synthetic dirty images (zero dependencies)
python scripts/generate_synthetic_data.py --num_variations 5

# Option 2: Add real-world Kaggle data (optional, requires API key)
# 1. Get credentials from https://kaggle.com/account
# 2. Set KAGGLE_USERNAME and KAGGLE_KEY in .env
python scripts/download_data.py --download-kaggle
```

### Training Configuration
```bash
# Basic training with default settings
python src/train.py

# Custom configuration for different constraints
python src/train.py --model_type custom_cnn --epochs 10 --batch_size 16    # CPU training
python src/train.py --model_type resnet50 --epochs 20 --batch_size 32      # GPU training
python src/train.py --model_type mobilenet --epochs 15 --batch_size 8      # Mobile deployment
```

## ğŸ“š Documentation

- **[ğŸ—ï¸ Architecture](docs/ARCHITECTURE.md)** - Model architectures and technical implementation
- **[ğŸ¨ Synthetic Data](docs/SYNTHETIC_DATA.md)** - Complete guide to synthetic data generation pipeline
- **[ğŸ“ Training Guide](docs/TRAINING_GUIDE.md)** - Training optimization and strategies for various constraints
- **[ğŸ“‹ API Reference](docs/API_REFERENCE.md)** - Complete Python API and CLI documentation

## ğŸ¯ What Makes This Revolutionary

### Advanced Synthetic Data Generation
Unlike traditional approaches requiring large labeled datasets, our system generates **unlimited realistic training data** from minimal clean images:

- **Controlled Quality**: Precise control over dirt types, intensity, and distribution
- **Zero Dependencies**: Works immediately without external datasets or APIs
- **Perfect Balance**: Generate exactly the data ratio needed for optimal training
- **Realistic Appearance**: Multiple stain types with proper lighting and texture effects

### Resource-Efficient Training
Optimized for practical development environments:

- **Local Training**: Complete training in <5 minutes on regular laptops
- **Multiple Strategies**: CPU-only, balanced, and high-performance configurations
- **Smart Optimization**: Gradient accumulation, mixed precision, early stopping
- **Memory Efficient**: Works with limited RAM through batch size optimization

### Production-Ready Deployment
Built for real-world applications:

- **High Confidence**: Reliable probability calibration (0.78-1.00 range)
- **Multiple Interfaces**: Python API, CLI, and web integration examples
- **Visualization Tools**: Prediction overlays and confidence displays
- **Error Handling**: Robust error recovery and batch processing

## ğŸ› ï¸ Requirements

- **Python**: 3.8+
- **Memory**: 4GB RAM (8GB recommended)
- **Storage**: 2GB free space
- **GPU**: Optional (NVIDIA GPU accelerates training)

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸŒŸ Support

- **ğŸ“§ Email**: [joshamorrison@gmail.com](mailto:joshamorrison@gmail.com)
- **ğŸ’¼ LinkedIn**: [linkedin.com/in/joshamorrison](https://www.linkedin.com/in/joshamorrison)
- **ğŸ™ GitHub**: [github.com/joshamorrison](https://github.com/joshamorrison)

---

**â­ Found this valuable? Star the repo and share with your network!**

*Revolutionary computer vision system with synthetic data generation - solving real-world classification challenges without massive datasets!* ğŸ”âœ¨