# Generative Econometric Forecasting Platform
# Environment Configuration Template
# Copy this file to .env and fill in your actual values

# =====================================
# REQUIRED API KEYS
# =====================================

# FRED API Key (Federal Reserve Economic Data)
# Get your free key at: https://fred.stlouisfed.org/docs/api/api_key.html
FRED_API_KEY=your_fred_api_key_here

# OpenAI API Key (for AI narratives and demand planning)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# LangChain API Key (for enhanced monitoring)
# Get your key at: https://smith.langchain.com/
LANGCHAIN_API_KEY=your_langchain_api_key_here

# News API Key (for economic news sentiment analysis)
# Get your free key at: https://newsapi.org/register
NEWSAPI_KEY=your_newsapi_key_here

# Nixtla API (TimeGPT) - OPTIONAL for foundation model forecasting
# Get key at: https://nixtla.io/
NIXTLA_API_KEY=your_nixtla_api_key_here

# Alpha Vantage - OPTIONAL for additional financial data
# Get free key at: https://www.alphavantage.co/support/#api-key
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key_here

# =====================================
# AWS CONFIGURATION
# =====================================

# AWS credentials (required for cloud deployment)
AWS_ACCESS_KEY_ID=your_aws_access_key_id
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
AWS_DEFAULT_REGION=us-east-1

# AWS S3 Configuration
AWS_S3_BUCKET_DATA=econometric-forecasting-data
AWS_S3_BUCKET_MODELS=econometric-forecasting-models
AWS_S3_BUCKET_OUTPUTS=econometric-forecasting-outputs

# AWS Lambda Configuration
AWS_LAMBDA_TIMEOUT=300
AWS_LAMBDA_MEMORY=1024

# AWS EC2 Configuration (for Airflow and R processing)
AWS_EC2_INSTANCE_TYPE=t3.medium
AWS_EC2_KEY_PAIR=your-ec2-keypair-name

# =====================================
# R INTEGRATION CONFIGURATION
# =====================================

# R Installation Path (Windows example, adjust for your OS)
R_HOME=C:\Program Files\R\R-4.3.0
R_USER=C:\Users\YourUser\Documents

# R Package Configuration
R_PACKAGES_REQUIRED=vars,forecast,urca,VARselect,tseries
R_AUTO_INSTALL_PACKAGES=true

# R Memory Configuration
R_MAX_MEMORY=8192M
R_ENABLE_PARALLEL=true

# =====================================
# APACHE AIRFLOW CONFIGURATION
# =====================================

# Airflow Database Connection
AIRFLOW_DATABASE_URL=postgresql://airflow:password@localhost:5432/airflow

# Airflow Core Settings
AIRFLOW_EXECUTOR=LocalExecutor
AIRFLOW_PARALLELISM=16
AIRFLOW_MAX_ACTIVE_RUNS_PER_DAG=1

# Airflow Security
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_PASSWORD=your_airflow_admin_password
AIRFLOW_SECRET_KEY=your_airflow_secret_key_here

# Airflow Email Configuration (optional)
AIRFLOW_SMTP_HOST=smtp.gmail.com
AIRFLOW_SMTP_PORT=587
AIRFLOW_SMTP_USER=your_email@gmail.com
AIRFLOW_SMTP_PASSWORD=your_email_password

# =====================================
# LANGSMITH ENHANCED MONITORING
# =====================================

# LangSmith Project Configuration
LANGSMITH_PROJECT=econometric-forecasting
LANGSMITH_ENVIRONMENT=production

# Enhanced Monitoring Settings
LANGSMITH_ENABLE_CUSTOM_METRICS=true
LANGSMITH_TRACE_FORECASTING=true
LANGSMITH_TRACE_SENSITIVITY=true
LANGSMITH_TRACE_SCENARIOS=true

# Performance Tracking
LANGSMITH_PERFORMANCE_THRESHOLD=5.0
LANGSMITH_QUALITY_THRESHOLD=0.85
LANGSMITH_COST_TRACKING=true

# =====================================
# CAUSAL INFERENCE CONFIGURATION
# =====================================

# Causal Models Configuration
CAUSAL_INFERENCE_METHOD=double_ml
CAUSAL_CONFIDENCE_LEVEL=0.95
CAUSAL_BOOTSTRAP_SAMPLES=1000

# Treatment Effect Analysis
ENABLE_POLICY_ANALYSIS=true
ENABLE_COUNTERFACTUAL_FORECASTING=true
CAUSAL_DISCOVERY_METHOD=granger

# Model Performance
CAUSAL_MODEL_SELECTION=auto
CAUSAL_CROSS_VALIDATION_FOLDS=5

# =====================================
# SCENARIO ANALYSIS CONFIGURATION
# =====================================

# High-Performance Engine Settings
SCENARIO_MAX_WORKERS=4
SCENARIO_CACHE_ENABLED=true
SCENARIO_VECTORIZED_OPERATIONS=true

# Scenario Generation
DEFAULT_SCENARIOS=baseline,recession,expansion,stagflation,financial_crisis,supply_shock
SCENARIO_MONTE_CARLO_SIMULATIONS=1000
SCENARIO_FORECAST_HORIZON=12

# Performance Optimization
SCENARIO_SPEED_OPTIMIZATION=true
SCENARIO_PARALLEL_PROCESSING=true

# =====================================
# SENSITIVITY TESTING CONFIGURATION
# =====================================

# LLM-Based Analysis
SENSITIVITY_LLM_MODEL=gpt-4
SENSITIVITY_LLM_TEMPERATURE=0.3
SENSITIVITY_AUTO_INTERPRETATION=true

# Testing Parameters
SENSITIVITY_PERTURBATIONS=-0.5,-0.25,-0.1,0.1,0.25,0.5
SENSITIVITY_CRITICAL_PARAMS=gdp_growth,inflation_rate,unemployment_rate,interest_rate,consumer_confidence

# Interaction Effects
ENABLE_PARAMETER_INTERACTIONS=true
SENSITIVITY_INTERACTION_THRESHOLD=0.1

# =====================================
# MODEL CONFIGURATION
# =====================================

# Forecasting Settings
DEFAULT_FORECAST_HORIZON=12
DEFAULT_START_DATE=2010-01-01
AUTO_MODEL_SELECTION=true
ENSEMBLE_MODELS=arima,prophet,neural,r_models

# Economic Indicators (comma-separated)
DEFAULT_INDICATORS=gdp,unemployment,inflation,interest_rate,consumer_confidence
CUSTOM_INDICATORS=

# Model Performance
CONFIDENCE_LEVEL=0.95
MIN_DATA_POINTS=50
MAX_MISSING_PCT=20.0
MODEL_SELECTION_METRIC=aic
CROSS_VALIDATION_FOLDS=5

# =====================================
# AI NARRATIVE & DEMAND PLANNING
# =====================================

# AI Model Configuration
NARRATIVE_MODEL=gpt-3.5-turbo
NARRATIVE_TEMPERATURE=0.3
EXECUTIVE_SUMMARY_LENGTH=medium

# Demand Planning Settings
SCENARIO_COUNT=3
DEFAULT_INDUSTRY=retail
CUSTOMER_CONTEXT=B2C retail customers
ENABLE_DEMAND_PLANNING=true

# Customer Segmentation
SEGMENT_TYPES=price_sensitive,premium,business,essential
ECONOMIC_SENSITIVITY_LEVELS=high,medium,low

# =====================================
# OUTPUT CONFIGURATION
# =====================================

# File Output Settings
OUTPUT_DIRECTORY=outputs
SAVE_CHARTS=true
SAVE_JSON_REPORTS=true
SAVE_EXECUTIVE_SUMMARIES=true
SAVE_DEMAND_REPORTS=true
SAVE_CAUSAL_ANALYSIS=true
SAVE_SCENARIO_REPORTS=true
SAVE_SENSITIVITY_REPORTS=true

# Chart Configuration
CHART_DPI=300
CHART_FORMAT=png
INCLUDE_CONFIDENCE_INTERVALS=true

# =====================================
# APPLICATION SETTINGS
# =====================================

# Development Settings
DEBUG=false
LOG_LEVEL=INFO
CACHE_FORECASTS=true
CACHE_TTL_HOURS=24

# Performance Settings
MAX_WORKERS=4
TIMEOUT_SECONDS=300
RETRY_ATTEMPTS=3
MAX_ARIMA_ORDER=5
ENABLE_PARALLEL_PROCESSING=true
CACHE_MODEL_RESULTS=true

# =====================================
# MONITORING & ALERTS
# =====================================

# Performance Tracking
ENABLE_PERFORMANCE_TRACKING=true
FORECAST_ACCURACY_THRESHOLD=85.0
DEMAND_SCENARIO_MIN_PROBABILITY=0.05

# Alerting (Optional)
ALERT_EMAIL=your_email@example.com
SLACK_WEBHOOK=your_slack_webhook_url
ENABLE_EMAIL_ALERTS=false
ENABLE_SLACK_ALERTS=false

# CloudWatch Monitoring (AWS)
ENABLE_CLOUDWATCH_METRICS=false
CLOUDWATCH_NAMESPACE=EconometricForecasting
CLOUDWATCH_LOG_GROUP=/aws/lambda/econometric-forecasting

# =====================================
# ADVANCED SETTINGS
# =====================================

# Data Validation
ENABLE_DATA_QUALITY_CHECKS=true
OUTLIER_DETECTION_THRESHOLD=3.0
MISSING_VALUE_STRATEGY=forward_fill

# Model Performance
ENSEMBLE_WEIGHTS=equal
USE_ENSEMBLE_FORECASTING=true

# Business Rules
INVENTORY_BASELINE=100.0
DEMAND_VARIANCE_THRESHOLD=5.0
SCENARIO_PROBABILITY_THRESHOLD=0.1

# Security Settings
ENABLE_API_RATE_LIMITING=true
API_RATE_LIMIT=100
ENABLE_REQUEST_LOGGING=true

# =====================================
# LEGACY SETTINGS (for backward compatibility)
# =====================================

DEFAULT_CONFIDENCE_LEVEL=0.95
SAVE_PLOTS=true
PLOT_FORMAT=png
LOG_FILE=forecasting.log